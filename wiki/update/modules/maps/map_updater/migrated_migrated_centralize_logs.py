from unicode_aliases import *
# Constantes
MAX_RETRIES = 8

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script Migrado: migrated_centralize_logs.py
M√≥dulo de Destino: maps.map_updater
Data de Migra√ß√£o: 2025-08-01 12:21:36

Script original migrado para a estrutura modular unificada.
"""

# Imports do m√≥dulo
from . import MapupdaterModule

# Conte√∫do original do script
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script Migrado: centralize_logs.py
M√≥dulo de Destino: tools.log_manager
Data de Migra√ß√£o: 2025-08-01 12:21:34

Script original migrado para a estrutura modular unificada.
"""

# Imports do m√≥dulo
from . import LogmanagerModule

# Conte√∫do original do script
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sistema de Logs Centralizado
============================

Este script centraliza e organiza logs espalhados em sistema centralizado
com categoriza√ß√£o autom√°tica e estrutura hier√°rquica.

Autor: Sistema BMAD - Log Organizer
Data: 2025-08-01
"""

import json
import shutil
from datetime import datetime
import logging

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class LogCentralizer:
    """Centralizador de logs BMAD"""
    
    def __init__(self, log_dir: str = "wiki/log"):
        """
        Inicializa o centralizador de logs.
        
        Args:
            log_dir: Diret√≥rio principal de logs
        """
        self.log_dir = Path(log_dir)
        self.backup_dir = self.log_dir / "backup_centralization"
        self.backup_dir.mkdir(exist_ok=True)
        
        # Estrutura de categoriza√ß√£o
        self.log_categories = {
            "agents": {
                "description": "Logs de agentes BMAD",
                "patterns": ["*_agent.log", "*_agent_*.log"],
                "subcategories": {
                    "core_agents": ["professor_agent.log", "task_supervisor_agent.log", "quality_assurance_agent.log"],
                    "navigation_agents": ["json_navigation_agent.log", "graph_navigation_agent.log",
    "integrated_navigation_agent.log"],
                    "documentation_agents": ["documentation_agent.log", "documentation_completer.log"],
                    "module_agents": ["module_creator.log", "module_generator.log", "module_analyzer.log",
    "module_tester.log"],
                    "git_agents": ["git_automation.log", "git_automation_fixed.log"],
                    "research_agents": ["researcher_agent.log", "canary_researcher.log"],
                    "integration_agents": ["integration_agent.log", "integration_system.log"],
                    "validation_agents": ["path_validator_agent.log", "comprehensive_path_validator.log"],
                    "organization_agents": ["intelligent_organization.log", "habdel_organization.log"],
                    "analysis_agents": ["deep_source_analyzer.log", "dashboard_creation.log"]
                }
            },
            "reports": {
                "description": "Relat√≥rios de execu√ß√£o",
                "patterns": ["*_report.md", "*_report.json", "*_report_*.md", "*_report_*.json"],
                "subcategories": {
                    "task_reports": ["*task*", "*Task*"],
                    "workflow_reports": ["*workflow*", "*Workflow*"],
                    "validation_reports": ["*validation*", "*Validation*"],
                    "education_reports": ["*education*", "*Education*", "*professor*", "*Professor*"],
                    "integration_reports": ["*integration*", "*Integration*"],
                    "organization_reports": ["*organization*", "*Organization*"],
                    "progress_reports": ["*progress*", "*Progress*"],
                    "analysis_reports": ["*analysis*", "*Analysis*", "*analise*", "*Analise*"]
                }
            },
            "system": {
                "description": "Logs do sistema",
                "patterns": ["auto_*.log", "auto_*.json", "script_*.json", "python_*.json"],
                "subcategories": {
                    "optimization": ["auto_optimizer.log", "auto_optimization_history.json"],
                    "script_executions": ["script_executions.json", "python_error_resolutions.json"],
                    "system_status": ["readme_status_report.json", "orchestration_report_*.json"]
                }
            },
            "archives": {
                "description": "Arquivos arquivados",
                "patterns": ["*.md", "*.json"],
                "subcategories": {
                    "plans": ["*plano*", "*Plano*", "*plan*", "*Plan*"],
                    "final_reports": ["*final*", "*Final*"],
                    "corrections": ["*correcao*", "*Correcao*", "*correction*", "*Correction*"],
                    "improvements": ["*improvement*", "*Improvement*", "*melhoria*", "*Melhoria*"]
                }
            }
        }
        
        # Estrutura de diret√≥rios centralizada
        self.centralized_structure = {
            "agents": self.log_dir / "agents",
            "reports": self.log_dir / "reports",
            "system": self.log_dir / "system",
            "archives": self.log_dir / "archives",
            "temp": self.log_dir / "temp",
            "backup": self.log_dir / "backup"
        }
        
    def create_centralized_structure(self) -> bool:
        """Cria estrutura centralizada de logs"""
        logger.info("üìÅ Criando estrutura centralizada...")
        
        try:
            # Criar diret√≥rios principais
            for category, path in self.centralized_structure.items():
                path.mkdir(exist_ok=True)
                logger.info(f"‚úÖ Diret√≥rio criado: {path}")
            
            # Criar subcategorias
            for category_name, category_config in self.log_categories.items():
                category_path = self.centralized_structure[category_name]
                
                for subcategory in category_config.get("subcategories", {}).keys():
                    subcategory_path = category_path / subcategory
                    subcategory_path.mkdir(exist_ok=True)
                    logger.info(f"‚úÖ Subcategoria criada: {subcategory_path}")
            
            return True
            
        except Exception as e:
            logger.error(f"Erro ao criar estrutura: {e}")
            return False
    
    def categorize_file(self, filename: str) -> Dict[str, str]:
        """Categoriza um arquivo de log"""
        filename_lower = filename.lower()
        
        for category_name, category_config in self.log_categories.items():
            # Verificar padr√µes da categoria
            for pattern in category_config["patterns"]:
                if self.matches_pattern(filename, pattern):
                    # Encontrar subcategoria
                    subcategory = "general"
                    for subcat_name, subcat_patterns in category_config.get("subcategories", {}).items():
                        for pattern in subcat_patterns:
                            if self.matches_pattern(filename, pattern):
                                subcategory = subcat_name
                                break
                        if subcategory != "general":
                            break
                    
                    return {
                        "category": category_name,
                        "subcategory": subcategory,
                        "description": category_config["description"]
                    }
        
        # Arquivo n√£o categorizado
        return {
            "category": "archives",
            "subcategory": "uncategorized",
            "description": "Arquivo n√£o categorizado"
        }
    
    def matches_pattern(self, filename: str, pattern: str) -> bool:
        """Verifica se arquivo corresponde ao padr√£o"""
        import fnmatch
        
        # Converter padr√µes simples para fnmatch
        if "*" in pattern:
            return fnmatch.fnmatch(filename, pattern)
        else:
            return filename == pattern
    
    def backup_existing_files(self) -> bool:
        """Faz backup dos arquivos existentes"""
        logger.info("üíæ Fazendo backup dos arquivos existentes...")
        
        try:
            # Fazer backup de todos os arquivos no diret√≥rio de logs
            for file_path in self.log_dir.rglob("*"):
                if file_path.is_file() and file_path.parent != self.backup_dir:
                    # Criar estrutura de backup
                    relative_path = file_path.relative_to(self.log_dir)
                    backup_path = self.backup_dir / relative_path
                    backup_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Copiar arquivo
                    shutil.copy2(file_path, backup_path)
            
            logger.info("‚úÖ Backup conclu√≠do")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao fazer backup: {e}")
            return False
    
    def move_file_to_category(self, file_path: Path, category: str, subcategory: str) -> bool:
        """Move arquivo para categoria apropriada"""
        try:
            # Determinar destino
            if category in self.centralized_structure:
                dest_dir = self.centralized_structure[category] / subcategory
                dest_dir.mkdir(parents=True, exist_ok=True)
                
                dest_file = dest_dir / file_path.name
                
                # Se arquivo j√° existe, adicionar timestamp
                if dest_file.exists():
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    name_parts = file_path.stem, timestamp, file_path.suffix
                    dest_file = dest_dir / f"{name_parts[0]}_{name_parts[1]}{name_parts[2]}"
                
                # Mover arquivo
                shutil.move(str(file_path), str(dest_file))
                logger.info(f"üìÅ Movido: {file_path.name} ‚Üí {category}/{subcategory}/")
                return True
            else:
                logger.warning(f"Categoria n√£o encontrada: {category}")
                return False
                
        except Exception as e:
            logger.error(f"Erro ao mover {file_path}: {e}")
            return False
    
    def centralize_logs(self) -> Dict[str, Any]:
        """Centraliza todos os logs"""
        logger.info("üöÄ Iniciando centraliza√ß√£o de logs...")
        
        # Fazer backup primeiro
        if not self.backup_existing_files():
            return {"error": "Falha no backup"}
        
        # Criar estrutura centralizada
        if not self.create_centralized_structure():
            return {"error": "Falha na cria√ß√£o da estrutura"}
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "files_processed": 0,
            "files_categorized": 0,
            "files_moved": 0,
            "errors": [],
            "categories": {}
        }
        
        # Processar todos os arquivos
        for file_path in self.log_dir.rglob("*"):
            if file_path.is_file() and file_path.parent != self.backup_dir:
                results["files_processed"] += 1
                
                try:
                    # Categorizar arquivo
                    categorization = self.categorize_file(file_path.name)
                    category = categorization["category"]
                    subcategory = categorization["subcategory"]
                    
                    # Registrar categoria
                    if category not in results["categories"]:
                        results["categories"][category] = {}
                    if subcategory not in results["categories"][category]:
                        results["categories"][category][subcategory] = []
                    
                    results["categories"][category][subcategory].append(file_path.name)
                    results["files_categorized"] += 1
                    
                    # Mover arquivo
                    if self.move_file_to_category(file_path, category, subcategory):
                        results["files_moved"] += 1
                    else:
                        results["errors"].append(f"Falha ao mover: {file_path.name}")
                
                except Exception as e:
                    error_msg = f"Erro ao processar {file_path.name}: {e}"
                    results["errors"].append(error_msg)
                    logger.error(error_msg)
        
        # Criar √≠ndice centralizado
        self.create_centralized_index(results)
        
        logger.info(f"‚úÖ Centraliza√ß√£o conclu√≠da!")
        logger.info(f"üìä Arquivos processados: {results['files_processed']}")
        logger.info(f"üìä Arquivos categorizados: {results['files_categorized']}")
        logger.info(f"üìä Arquivos movidos: {results['files_moved']}")
        
        return results
    
    def create_centralized_index(self, results: Dict[str, Any]) -> bool:
        """Cria √≠ndice centralizado dos logs"""
        try:
            index_data = {
                "timestamp": datetime.now().isoformat(),
                "total_files": results["files_processed"],
                "categories": results["categories"],
                "structure": {
                    "agents": "Logs de agentes BMAD",
                    "reports": "Relat√≥rios de execu√ß√£o",
                    "system": "Logs do sistema",
                    "archives": "Arquivos arquivados",
                    "temp": "Arquivos tempor√°rios",
                    "backup": "Backups"
                }
            }
            
            # Salvar √≠ndice
            index_file = self.log_dir / "centralized_logs_index.json"
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üìã √çndice centralizado criado: {index_file}")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao criar √≠ndice: {e}")
            return False
    
    def generate_centralization_report(self, results: Dict[str, Any]) -> str:
        """Gera relat√≥rio de centraliza√ß√£o"""
        report = f"""# Relat√≥rio de Centraliza√ß√£o de Logs

## üìä Resumo da Centraliza√ß√£o

- **Data**: {results['timestamp']}
- **Arquivos Processados**: {results['files_processed']}
- **Arquivos Categorizados**: {results['files_categorized']}
- **Arquivos Movidos**: {results['files_moved']}

## üìÅ Estrutura Centralizada

### Agents
Logs de agentes BMAD organizados por especializa√ß√£o.

### Reports
Relat√≥rios de execu√ß√£o categorizados por tipo.

### System
Logs do sistema e automa√ß√µes.

### Archives
Arquivos arquivados e hist√≥ricos.

### Temp
Arquivos tempor√°rios.

### Backup
Backups de seguran√ßa.

## üìã Categoriza√ß√£o Detalhada

"""
        
        for category, subcategories in results["categories"].items():
            report += f"### {category.title()}\n\n"
            for subcategory, files in subcategories.items():
                report += f"#### {subcategory.replace('_', ' ').title()}\n"
                report += f"- Arquivos: {len(files)}\n"
                for file in files[:5]:  # Mostrar apenas os primeiros 5
                    report += f"  - {file}\n"
                if len(files) > 5:
                    report += f"  - ... e mais {len(files) - 5} arquivos\n"
                report += "\n"
        
        if results["errors"]:
            report += "## ‚ùå Erros\n\n"
            for error in results["errors"]:
                report += f"- {error}\n"
        
        report += f"""
## üìÅ Backup

Todos os arquivos originais foram salvos em: `wiki/log/backup_centralization/`

## üéØ Resultado

A centraliza√ß√£o organizou **{results['files_processed']}** arquivos em estrutura hier√°rquica,
facilitando navega√ß√£o e manuten√ß√£o dos logs do sistema BMAD.
"""
        
        return report

def main():
    """Fun√ß√£o principal"""
    print("üöÄ Sistema de Logs Centralizado")
    print("=" * 50)
    
    centralizer = LogCentralizer()
    
    # Centralizar logs
    results = centralizer.centralize_logs()
    
    if "error" in results:
        print(f"‚ùå Erro: {results['error']}")
        return
    
    # Gerar relat√≥rio
    report = centralizer.generate_centralization_report(results)
    
    # Salvar relat√≥rio
    report_file = centralizer.log_dir / "centralization_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    # Salvar resultados JSON
    results_file = centralizer.log_dir / "centralization_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìã Relat√≥rio salvo em: {report_file}")
    print(f"üìä Resultados salvos em: {results_file}")
    
    print(f"\nüìä Resumo:")
    print(f"   Arquivos processados: {results['files_processed']}")
    print(f"   Arquivos categorizados: {results['files_categorized']}")
    print(f"   Arquivos movidos: {results['files_moved']}")
    print(f"   Categorias criadas: {len(results['categories'])}")
    
    print("‚úÖ Sistema de logs centralizado implementado!")

if __name__ == "__main__":
    main() 

# Fun√ß√£o de integra√ß√£o com o m√≥dulo
def integrate_with_module():
    """Integra o script com o m√≥dulo de destino."""
    module = LogmanagerModule()
    return module.execute()

if __name__ == "__main__":
    # Executar integra√ß√£o com m√≥dulo
    result = integrate_with_module()
    if result:
        print(f"‚úÖ Script centralize_logs.py executado com sucesso via m√≥dulo tools.log_manager")
    else:
        print(f"‚ùå Erro na execu√ß√£o do script centralize_logs.py via m√≥dulo tools.log_manager")


# Fun√ß√£o de integra√ß√£o com o m√≥dulo
def integrate_with_module():
    """Integra o script com o m√≥dulo de destino."""
    module = MapupdaterModule()
    return module.execute()

if __name__ == "__main__":
    # Executar integra√ß√£o com m√≥dulo
    result = integrate_with_module()
    if result:
        print(f"‚úÖ Script migrated_centralize_logs.py executado com sucesso via m√≥dulo maps.map_updater")
    else:
        print(f"‚ùå Erro na execu√ß√£o do script migrated_centralize_logs.py via m√≥dulo maps.map_updater")
